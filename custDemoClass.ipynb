{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blackwell Project: Understanding Customers: Task 2\n",
    "\n",
    "Background\n",
    "* VP of sales (Goodrich) believes:\n",
    "    * Customers who shop in-store are older\n",
    "    * Older customers spend more\n",
    "* Considering marketing activities and changes to website to attract older customers.\n",
    "* Wants to better understand age of customers, and if age correlates with how much they spend. \n",
    "\n",
    "Danielle's Questions:\n",
    "1. Are their differences in customer age between regions?\n",
    "2. Can we predict the age of a customer in a region based on demographic data?\n",
    "3. Is there any correlation between the customer's age and whether their transaction was online or in-store?\n",
    "4. Do any other factors predict whether customers will buy online or in-store?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DS Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#SKLearn Stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "#helpers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "data = pd.read_csv('Demographic_Data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data (again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for duplicate observations/cases\n",
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate observations from the dataset\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at number of entries to see how many duplicates we dropped\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes*\n",
    "\n",
    "* i was hoping to get information on any duplicate entries in the data frame before i drop duplicates in the next step. need to find another command.\n",
    "* figure out how to output and save a processed version of the data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Normalization\n",
    "* experiments have shown that ML and deep learning models perform \"way better\" on data that is normally distributed\n",
    "* the goal of normalization is to transform the values in the dataset so they ***all have a common scale*** without distorting differences between the range of values\n",
    "* there are several ways to normalize data. in this example, i'll use the standard scaler model. \n",
    "* see [easy guide to data preprocessing in python](https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the independent variables (features/attributes) for the model \n",
    "X = data.iloc[:, 0:4]\n",
    "print('Summary of feature sample')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the dependent variable (target) for the model\n",
    "y = data['region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split datasets into a training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30,\n",
    "                                                   random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes*  \n",
    "* ```test_size = .30``` parameter is specifying that 70% of the dataset should be for training the model, and 30% should be for testing the model\n",
    "* ```random_state = 123``` ensures that the same observations will be selected for the training and test sets each time the cell is run/re-run. the number 123 does not mean anything, you could use any other number in its place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instatiate the decision tree algorithm \n",
    "algo = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "#train the model on the training data set\n",
    "model = algo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model on testing data to see how good the predictions are\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create classification report on how well model did on the testing data\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create confusion matrix showing model predictions for each class\n",
    "print(metrics.confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes*\n",
    "* in this example our goal is to use ML to train the decision tree classifier model to predict the region of each purchase based on the other four features in the dataset.\n",
    "* ```X_train, x_test, y_train, y_test = train_test_split...``` split the data into a training set (```X_train, y_train```)—which the model trains on—and a testing set—which we will test the model on to see how well it does in predicting which 'region' each transaction is from.\n",
    "* ```preds = model.predict(X_test)```is where we are giving our trained model some new sets of X values (```X_test```) and asking it predict what region each is from.\n",
    "* in ```print(classification_report(y_test, preds))``` we are comparing the prediction the model made for each observation in X_test, comparing the predicted region to the actual region for each observation (i.e. the values in ```y_test```), and generating a classification report\n",
    "* understanding the classification report: precison = the true positives/true positives + false positives; recall = true positives/true positives + false negatives' f1-score = a balance between precision and recall; support = the number of observations in X_test that were in each region. \n",
    "* accuracy = number of correct predictions/ total number of predictions\n",
    "    * accuracy is only meaningful if x_test is roughly balanced between the classes. just suppose 98% of the observations were in region 1, then the model could get 98% accuracy just by predicting that all observations are from region 1.\n",
    "* the confusion matrix is telling us for the observations actually from each region (rows), how many the model predicted in each region (e.g. for the cases actually in region 1, the model predicted 3,266 were in 1, 0 were in 2, 494 were in 3, and 1078 were in 4)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### visually plot the decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree #this should be at top with other imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the decision tree \n",
    "fig = plt.figure(figsize=(30,15))\n",
    "tree = plot_tree(model, max_depth=3, feature_names=X.columns, \n",
    "                 class_names =['0','1', '2','3'],\n",
    "                 filled = True, fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphviz creates better visualizations of decision trees\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn pkg also needed to plot tree using graphviz\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print a text-only representation of the decison tree model\n",
    "text_representation = tree.export_text(model)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change y values into strings because graphviz requires dv to be strings\n",
    "y_str=y.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#apply the graphviz tree plotting function to my model and data\n",
    "dot_data = tree.export_graphviz(model, max_depth=3,  \n",
    "                                feature_names=X.columns,  \n",
    "                                class_names=y_str,\n",
    "                                filled=True)\n",
    "# Draw graph\n",
    "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "pydot_graph.set_size('\"8,8!\"')\n",
    "#pydot_graph.write_png('resized_tree.png')\n",
    "\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output a .png file of graphviz tree & save to directory with jup nb\n",
    "graph.render(\"decision_tree_graphivz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes*\n",
    "* investigate In(19). i'm not sure what pydot_graph and graph lines are doing or if i need them.\n",
    "* ```tree = plot_tree(model, max_depth=3, feature_names=X.columns, \n",
    "                 class_names =['0','1', '2','3'], filled = True, fontsize=14)``` displays a visual plot of the model. \n",
    "* because that version of the tree was a bit crowded after i increased the fontsize of the nodes/leaves, i plotted the tree using the graphviz pkg. \n",
    "* the nodes of the tree tells us what feature-value the model splits the data at during each iteration (e.g. it first splits the data using the amount <= to 499.95, the child nodes then tell us the data was split using the in-store <=0.5, and so on).\n",
    "* each node/leaf also tells us the gini co-efficient of that node. can't remember what that means, but i know lower is better. if a partition has all and only observations within a single region (in this example), the gini will be 0.\n",
    "* samples = tells us how many observations from the data set are in that partition, so as we move down a branch from top to bottom the sample = number should be getting smaller and smaller as the model partitions the data into smaller and smaller sections.\n",
    "* the value = line tells us how many observations are in each partition at that node/leaf. (e.g. in the age<= 55.5 node we find out that there are 4091 obs. in region 1, 0 in region 2, 3676 in region 3, and 2047 in region 4).\n",
    "* class = is telling us the what region the model is predicting (at that point in the tree) for all the observations in that partition...i'm not sure this make sense, review later.  \n",
    "* decision trees can also be plotted using the dtreeviz pkg—these are the best looking. for more info see [this github post](https://github.com/parrt/dtreeviz)  \n",
    "¿ can/how do you recover the accuracy score for the model from the plot of the decision tree? \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gini → entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing default gini criterion to entropy\n",
    "algo_ent = DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "\n",
    "#train the decision tree algorithm on the training data\n",
    "model_ent = algo_ent.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model on X_test and predict values in y_test \n",
    "preds_ent = model_ent.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check model's predicted values against actual values (ground truth) in y_test \n",
    "#and report the results\n",
    "print(classification_report(y_test, preds_ent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes*\n",
    "* gini is the default for the model and is a measure of impurity\n",
    "* entropy is a measure of information gain\n",
    "* both gini and entropy are measures of information gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth 3 → 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change max depth from 3 to 4\n",
    "algo_ent4 = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "\n",
    "#train the decision tree algorithm on the training data\n",
    "model_ent4 = algo_ent4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model on X_test and predict values in y_test \n",
    "preds_ent4 = model_ent4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check model's predicted values against actual values (ground truth) in y_test \n",
    "#and report the results\n",
    "print(classification_report(y_test, preds_ent4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes*  \n",
    "* these scores are identical to scores for max depth 3 model. not sure if that's b/c i did something wrong or the model doesn't gain any predictive power after depth 3\n",
    "    * ben said it's b/c the model doesn't improve beyond max depth 3\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### max depth 4 → 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change max depth from 4 to 1\n",
    "algo_ent1 = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "\n",
    "#train the decision tree algorithm on the training data\n",
    "model_ent1 = algo_ent1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model on X_test and predict values in y_test \n",
    "preds_ent1 = model_ent1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check model's predicted values against actual values (ground truth)\n",
    "#in y_test and report the results\n",
    "print(classification_report(y_test, preds_ent1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes*\n",
    "* i think this warning appeared because there were no observations in regions 3 & 4 after the split represented in the root node of the tree. but with max depth of the tree set to 1, there are no more splits in the data (***verify***)  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how does cross validation decrease the chance that a ML model will be overfit?\n",
    "* basically because you are testing and training the model on several smaller datasets (the folds), and then averaging the results of each of those to come up with the final model, it's more likely the overfitting will be smoothed out in the average. say the first model is overfit by .6, ***I DON'T THINK THIS IS CORRECT. I'VE DONE A LOT OF RESEARCH AND CANNOT FIND A SATISFACTORY ANSWER***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instatiate cross validation model with decision tree algorithm\n",
    "cv_model = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "#apply model with 3 fold to dataset\n",
    "scores = cross_val_score(cv_model, X, y, cv = 3)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean of accuracy scores from each fold\n",
    "avg_score = np.mean(scores)\n",
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply 4-fold-model to data\n",
    "scores = cross_val_score(cv_model, X, y, cv =4)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean of accuracy scores from each fold\n",
    "avg_score = np.mean(scores)\n",
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 8-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply 8-fold model to data\n",
    "scores = cross_val_score(cv_model, X, y, cv = 8)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean of accuracy scores from each fold\n",
    "avg_score = np.mean(scores)\n",
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 20-fold model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply 20 fold model to data\n",
    "scores = cross_val_score(cv_model, X, y, cv = 20)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean of accuracy scores from each fold\n",
    "avg_score = np.mean(scores)\n",
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes*  \n",
    "* i'm not sure how to choose the optimal number of folds. \n",
    "* i expected the accuracy of the model to improve at least slightly (up to a point) the more folds you used in the cv model because i was mistakenly thinking that in a cv model, the model was adjusted after being trained on each fold, so that after training the final model was basically the average of the models trained on each fold. \n",
    "* however, after talking to david i now know that is not how it works. \n",
    "* when you specify the type of algorithm (e.g. decision tree, random forest), set the various parameters, and specify your feature and target variables—the model is set. the model is not changed/refined in the training on each fold. the same model is used on every fold\n",
    "* but then how does cross validation cut the risk of overfitting? basically, the accuracy scores on each fold should be roughly the same. if one accuracy score is very different than the others, you know that something is going on with that part of the data and you need to investigate to figure it out. (***verify: i'm not sure about this***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try random forest and decision tree classifier models\n",
    "* to select the best model for our task, we should create, train, and test many different models based on different algorithms (e.g. 1NN, 3NN, KR-1, Random Forest) and then choose the one which one performs the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of preparing each model seperately, we can create a list\n",
    "#and do them all at once\n",
    "\n",
    "#create an empty list\n",
    "algos_class =[]\n",
    "\n",
    "#add random rorest classifier algorithm to empty list\n",
    "algos_class.append(('Random Forest Classifier', RandomForestClassifier()))\n",
    "print(algos_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add decision tree classifier algoritm to empty list\n",
    "algos_class.append(('Decision Tree Classifier', DecisionTreeClassifier()))\n",
    "print(algos_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list to hold the cross validation results for each model\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in algos_class: \n",
    "    result = cross_val_score(model, X, y, cv=3, scoring = 'accuracy')\n",
    "    names.append(name)\n",
    "    results.append(result)\n",
    "    \n",
    "for i in range(len(names)):\n",
    "    print(names[i], results[i].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes*  \n",
    "\n",
    "☼ IndentationError fix: i repeatedly got an indentation error when running ```for name, model in algos_class:``` i think b/c i didn't have a empty line after the ```results.append(result)```  \n",
    "\n",
    "☼ at first i could only get decision tree result to print, then realized i needed to embed second for loop within the first for loop. but now the random forest result is printing twice!\n",
    "\n",
    "¿would you choose the random forest or decision tree model for the project? why?\n",
    "* based on what i know now, i don't think i would choose either one because neither reaches the treshold of 75% accuracy. both models are little better than chance at predicting the region of a transaction. \n",
    "* i have since read that data scientists use occam's razor. so if two models have the same predictive power, you should always choose the simpiler one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# more Experimentation\n",
    "* make changes to the data, train the models on the altered data, and compare and contrast the results\n",
    "* ideally, your model should have > 75% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discretize age and use it as DV, experiment with different numbers of bins\n",
    "\n",
    "*feature_engine discretizer\n",
    "* ```EqualWidthDiscretiser```\n",
    "* pkg depends on sklearn KBinsDiscretizer\n",
    "\n",
    "*sklearn discretizer functions*\n",
    "* the equal width bins discretizer: ```discretizer_ew = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')``` \n",
    "* the equal frequency bins discretizer: ```discretizer_ef = KBinsDiscretizer(n_bins=3, encode=\"ordinal\", strategy='uniform')``` \n",
    "\n",
    "*pandas discretizer functions*\n",
    "* ```cut()```\n",
    "* ```qcut()```\n",
    "\n",
    "*numpy discretizer functions*\n",
    "* ```digitize```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pkgs needed to discretize variables\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from feature_engine.discretisers import EqualWidthDiscretiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*notes*  \n",
    "\n",
    "☼ install fix: first try feature_engine would not install because pkg was not found. then david helped me install it from the conda forge repo. in a conda terminal with the relevant ve activated, type ```conda install -c conda-forge feature_engine```\n",
    "* i asked about doing it with pip. he said avoid if possible b/c pip sometimes stores files in weird places and end up breaking later. so just install from conda repos if possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Discretize age — 3 bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the feature_engine equal width discretizer function and give\n",
    "#instructions on variable to discretize and how many bins to use\n",
    "disc_fe = EqualWidthDiscretiser(bins=3, variables = ['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the discretizer function to the X data\n",
    "disc_fe.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe that replaces age with the discretized version of age\n",
    "X_disc_age = disc_fe.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at first 5 rows of new dataframe to ensure the above process was successful\n",
    "X_disc_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list to hold the cross validation results for each model\n",
    "results_disc_age = []\n",
    "names_disc_age = []\n",
    "\n",
    "for name, model in algos_class: \n",
    "    result = cross_val_score(model, X_disc_age, y, cv=3, scoring = 'accuracy')\n",
    "    names_disc_age.append(name)\n",
    "    results_disc_age.append(result)\n",
    "    \n",
    "for i in range(len(names)):\n",
    "    print(names_disc_age[i], results_disc_age[i].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the feature_engine equal width discretizer function and give instructions on which\n",
    "#variable to discretize and how many bins to use\n",
    "disc_fe50 = EqualWidthDiscretiser(bins=50, variables = ['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the discretizer function to the X data\n",
    "disc_fe50.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe that replaces age with the discretized version of age\n",
    "X_disc_age50 = disc_fe50.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_disc_age50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = RandomForestClassifier()\n",
    "print(cross_val_score(cv_model, X_disc_age50, y, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### discretize amount and use it as the dv. can a useful model be constructed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps  \n",
    "1. re-order data so 'amount' is on right end of df\n",
    "2. specify features and target variables\n",
    "3. discretize 'amount' variable  \n",
    "    a. instantiate discretizer function  \n",
    "    b. apply disc. function to 'amount' var  \n",
    "    c. create new df with discretized amount var subbed in\n",
    "4. instantiate the decision tree cv model\n",
    "5. apply cv model to X and disc_y and print cross val score\n",
    "6. interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 1: reorder data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-order columns in df to put amount at the end\n",
    "data = data[['in-store', 'age', 'items', 'region', 'amount']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### step 2: specify features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set features of the model\n",
    "X = data.iloc[:, 0:4]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['amount']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### step 3: discretize amount variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate discretizer function\n",
    "disc = EqualWidthDiscretiser(bins=3, variables = ['amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply discretizer function to y\n",
    "disc.fit(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use two additional classification algorithms from sci-kit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what about items? are these even in the tree? why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what about classifying where a transaction took place?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature (dependent variable)hhh importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas and random forest model to see which features within the df are most important \n",
    "feature_imp = pd.series(model.feature_importances_, index=data.feature.names)\n",
    "    .sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course1-env",
   "language": "python",
   "name": "course1-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
